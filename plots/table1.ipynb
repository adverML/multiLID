{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0be57e-6e73-404d-b94c-0c083affa5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from numpy import random\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "home = str(Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bae7c8-dfac-4179-88a2-06c1b5137130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, y_train, X_test, y_test):\n",
    "    scaler  = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    clf = LogisticRegressionCV(n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat =    clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8323319-9c2f-4a2c-ae43-032b67edb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat =    clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8b3e8d54-85f9-4358-859b-26c5fc74e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state:  21\n",
      "random state:  30\n",
      "random state:  65\n"
     ]
    }
   ],
   "source": [
    "factor = 0.8\n",
    "nr_mean = 3\n",
    "mean_tables = []\n",
    "nr_samples=2000\n",
    "\n",
    "attacks = ['fgsm', 'bim', 'pgd', 'aa', 'df', 'cw']\n",
    "datasets = ['cifar10', 'cifar100', 'imagenet']\n",
    "models = ['wrn28-10', 'vgg16', 'wrn50-2']\n",
    "detectors = ['lid', 'multilid']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for it in range(nr_mean):\n",
    "    random_state = [21, 30, 65][it] # random.randint(100)\n",
    "    print(\"random state: \", random_state)\n",
    "    final_table = np.zeros((len(attacks), 2))\n",
    "    base_path = os.path.join(home, 'workspace/multiLID/data/extract/run_{}/'.format(it+1))\n",
    "    \n",
    "    results[it] = {}\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        if dataset == 'imagenet':\n",
    "            k=30\n",
    "        else:\n",
    "            k=20\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            \n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "                \n",
    "            if not dataset in results[it]:\n",
    "                results[it][dataset] = {}\n",
    "            if not model in results[it][dataset]:\n",
    "                results[it][dataset][model] = {}\n",
    "                \n",
    "            #print(\"config: \", random_state, dataset, model)\n",
    "            \n",
    "            for detector in detectors:\n",
    "                \n",
    "                nor_fgsm  = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/fgsm/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_fgsm  = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/fgsm/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_bim   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/bim/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_bim   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/bim/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_pgd   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/pgd/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_pgd   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/pgd/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_aa    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/aa/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_aa    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/aa/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_df    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/df/k{k}/{detector}_normalos.pt\"))\n",
    "                adv_df    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/df/k{k}/{detector}_adverlos.pt\"))\n",
    "                nor_cw    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/cw/k{k}/{detector}_normalos.pt\"))\n",
    "                adv_cw    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/cw/k{k}/{detector}_adverlos.pt\"))\n",
    "\n",
    "                nor = [nor_fgsm, nor_bim, nor_pgd, nor_aa, nor_df, nor_cw]\n",
    "                adv = [adv_fgsm, adv_bim, adv_pgd, adv_aa, adv_df, adv_cw]\n",
    "\n",
    "                for rows in range(len(nor)):\n",
    "                    X_nor = nor[rows]\n",
    "                    X_adv = adv[rows]\n",
    "                    if len(X_nor.shape) > 2: \n",
    "                        X_nor = nor[rows].reshape((nor[rows].shape[0], -1))\n",
    "                        X_adv = adv[rows].reshape((adv[rows].shape[0], -1))\n",
    "\n",
    "                    y_nor = np.zeros(X_nor.shape[0]).astype('int')\n",
    "                    y_adv = np.ones(X_nor.shape[0]).astype('int')\n",
    "\n",
    "                    x_train_n, x_test_n, y_train_n, y_test_n = train_test_split(X_nor, y_nor, test_size=1-factor, train_size=factor, random_state=random_state)\n",
    "                    x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(X_adv, y_adv, test_size=1-factor, train_size=factor, random_state=random_state)\n",
    "\n",
    "                    X_train = np.concatenate((x_train_n, x_train_a))\n",
    "                    y_train = np.concatenate((y_train_n, y_train_a))\n",
    "\n",
    "                    X_test = np.concatenate((x_test_n, x_test_a))\n",
    "                    y_test = np.concatenate((y_test_n, y_test_a))\n",
    "\n",
    "                    if detector == 'lid':\n",
    "                        y_hat, y_hat_pr = LR(X_train, y_train, X_test, y_test)\n",
    "                    elif detector == 'multilid':\n",
    "                        y_hat, y_hat_pr = RF(X_train, y_train, X_test, y_test)\n",
    "\n",
    "                    auc = round(100*roc_auc_score(y_test, y_hat_pr), 2)\n",
    "                    f1 =  round(100*f1_score(y_test, y_hat), 2)\n",
    "     \n",
    "                    if not detector in results[it][dataset][model]:\n",
    "                        results[it][dataset][model][detector] = {}\n",
    "                    \n",
    "                    if not attacks[rows] in results[it][dataset][model][detector]: \n",
    "                        results[it][dataset][model][detector][attacks[rows]] = {}\n",
    "                    \n",
    "                    \n",
    "                    if not 'auc' in results[it][dataset][model][detector][attacks[rows]]:\n",
    "                        results[it][dataset][model][detector][attacks[rows]]['auc'] = {}\n",
    "                    if not 'f1' in results[it][dataset][model][detector][attacks[rows]]:\n",
    "                        results[it][dataset][model][detector][attacks[rows]]['f1' ] = {}\n",
    "                        \n",
    "                    results[it][dataset][model][detector][attacks[rows]]['auc'] = auc\n",
    "                    results[it][dataset][model][detector][attacks[rows]]['f1'] = f1                    \n",
    "\n",
    "                    # print(attacks[rows].upper(), '&' , auc, '&', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e74111-ee97-4fb9-bf13-23c6725d54fa",
   "metadata": {},
   "source": [
    "# LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "97bf8ab6-2bbe-48ec-bf1c-0c74b7ae8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_list_mean = []\n",
    "for it_mean in range(nr_mean):\n",
    "    lid_list = []\n",
    "    for dataset in ['cifar10', 'cifar100', 'imagenet']:\n",
    "        for model in ['wrn28-10', 'vgg16', 'wrn50-2']:\n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "            \n",
    "            tmp = np.zeros((len(attacks), 2))\n",
    "            for it, val in enumerate(results[it_mean][dataset][model]['lid'].items()):\n",
    "                #print(it, val)\n",
    "                tmp[it, 0] = val[1]['auc'].copy()\n",
    "                tmp[it, 1] = val[1]['f1'].copy()\n",
    "            lid_list.append(tmp.copy())\n",
    "    \n",
    "    lid_list_mean.append(np.stack(lid_list))\n",
    "lid_list_mean_res = np.stack(lid_list_mean)\n",
    "lid_mean = np.mean(lid_list_mean_res, axis=0)\n",
    "lid_var = np.var(lid_list_mean_res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d671e4af-b99b-4f77-aaae-84c0d5626b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{FGSM} & $97.16 \\pm 1.69$ & $90.66 \\pm 2.94$ & $88.10 \\pm 0.27$ & $79.53 \\pm 0.12$ & $98.18 \\pm 0.49$ & $93.47 \\pm 1.02$ & $77.97 \\pm 1.21$ & $70.79 \\pm 0.48$ & $71.38 \\pm 9.94$ & $65.77 \\pm 3.21$ \\\\\n",
      "\\textbf{BIM} & $87.09 \\pm 0.23$ & $79.70 \\pm 0.40$ & $93.00 \\pm 2.11$ & $85.10 \\pm 1.38$ & $95.63 \\pm 0.92$ & $89.05 \\pm 0.57$ & $81.57 \\pm 3.68$ & $73.85 \\pm 6.61$ & $94.45 \\pm 0.29$ & $87.24 \\pm 0.84$ \\\\\n",
      "\\textbf{PGD} & $89.25 \\pm 0.61$ & $80.43 \\pm 2.24$ & $90.40 \\pm 0.32$ & $81.52 \\pm 1.96$ & $97.82 \\pm 0.07$ & $91.97 \\pm 0.20$ & $85.27 \\pm 1.23$ & $78.88 \\pm 2.21$ & $96.21 \\pm 0.41$ & $89.72 \\pm 2.03$ \\\\\n",
      "\\textbf{AA} & $96.80 \\pm 0.42$ & $91.07 \\pm 0.85$ & $97.49 \\pm 0.15$ & $92.42 \\pm 0.34$ & $99.30 \\pm 0.02$ & $95.66 \\pm 0.57$ & $87.24 \\pm 1.02$ & $78.96 \\pm 0.07$ & $99.97 \\pm 0.00$ & $99.45 \\pm 0.11$ \\\\\n",
      "\\textbf{DF} & $95.38 \\pm 0.04$ & $87.79 \\pm 2.21$ & $86.48 \\pm 0.26$ & $77.13 \\pm 0.86$ & $57.04 \\pm 0.61$ & $53.08 \\pm 0.37$ & $54.41 \\pm 0.03$ & $53.18 \\pm 0.78$ & $54.67 \\pm 0.09$ & $49.75 \\pm 1.76$ \\\\\n",
      "\\textbf{CW} & $94.18 \\pm 0.15$ & $85.68 \\pm 0.17$ & $83.67 \\pm 0.33$ & $74.90 \\pm 0.60$ & $55.01 \\pm 0.31$ & $54.06 \\pm 4.29$ & $61.82 \\pm 1.00$ & $62.25 \\pm 2.02$ & $54.46 \\pm 0.04$ & $50.26 \\pm 4.79$ \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = \"\"\n",
    "for j in range(lid_mean.shape[1]):\n",
    "    latex_table += \"\\\\textbf{\"+f\"{attacks[j].upper()}\"+\"} & \"\n",
    "    for i in range(lid_mean.shape[0]):\n",
    "        mean = lid_mean[i, j, 0]\n",
    "        variance = lid_var[i, j, 0]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "        mean = lid_mean[i, j, 1]\n",
    "        variance = lid_var[i, j, 1]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "    latex_table = latex_table[:-2] + \"\\\\\\\\\\n\"\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cb3700-5eab-4df8-b490-7dc57a065b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4d09c5b4-36d6-4815-8b46-3f9c1f82d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_list_mean = []\n",
    "for it_mean in range(nr_mean):\n",
    "    lid_list = []\n",
    "    for dataset in ['cifar10', 'cifar100', 'imagenet']:\n",
    "        for model in ['wrn28-10', 'vgg16', 'wrn50-2']:\n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "            \n",
    "            tmp = np.zeros((len(attacks), 2))\n",
    "            for it, val in enumerate(results[it_mean][dataset][model]['multilid'].items()):\n",
    "                #print(it, val)\n",
    "                tmp[it, 0] = val[1]['auc'].copy()\n",
    "                tmp[it, 1] = val[1]['f1'].copy()\n",
    "            lid_list.append(tmp.copy())\n",
    "    \n",
    "    lid_list_mean.append(np.stack(lid_list))\n",
    "lid_list_mean_res = np.stack(lid_list_mean)\n",
    "lid_mean = np.mean(lid_list_mean_res, axis=0)\n",
    "lid_var = np.var(lid_list_mean_res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f42bc221-06c4-4041-b198-fc5d9706c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{FGSM} & $97.02 \\pm 0.20$ & $91.13 \\pm 0.77$ & $91.15 \\pm 0.13$ & $83.05 \\pm 1.95$ & $98.68 \\pm 0.16$ & $95.43 \\pm 1.23$ & $83.50 \\pm 1.01$ & $77.04 \\pm 0.54$ & $80.92 \\pm 0.81$ & $74.15 \\pm 0.14$ \\\\\n",
      "\\textbf{BIM} & $96.50 \\pm 0.26$ & $89.97 \\pm 0.52$ & $94.68 \\pm 0.11$ & $88.03 \\pm 1.06$ & $97.81 \\pm 0.08$ & $91.80 \\pm 0.08$ & $83.27 \\pm 0.42$ & $75.75 \\pm 2.19$ & $94.71 \\pm 0.45$ & $87.88 \\pm 0.22$ \\\\\n",
      "\\textbf{PGD} & $97.85 \\pm 0.09$ & $93.45 \\pm 0.05$ & $92.32 \\pm 1.31$ & $84.59 \\pm 1.92$ & $98.78 \\pm 0.05$ & $94.86 \\pm 1.17$ & $88.68 \\pm 0.21$ & $82.09 \\pm 0.67$ & $96.91 \\pm 0.14$ & $91.20 \\pm 0.15$ \\\\\n",
      "\\textbf{AA} & $99.64 \\pm 0.00$ & $97.48 \\pm 0.02$ & $98.76 \\pm 0.05$ & $95.09 \\pm 0.90$ & $99.88 \\pm 0.00$ & $98.62 \\pm 0.01$ & $91.60 \\pm 0.26$ & $85.32 \\pm 0.05$ & $99.88 \\pm 0.01$ & $99.00 \\pm 0.03$ \\\\\n",
      "\\textbf{DF} & $97.74 \\pm 0.14$ & $94.47 \\pm 0.11$ & $89.39 \\pm 1.53$ & $84.78 \\pm 1.10$ & $76.37 \\pm 0.15$ & $71.80 \\pm 1.52$ & $75.47 \\pm 1.12$ & $70.50 \\pm 0.94$ & $53.54 \\pm 1.31$ & $52.25 \\pm 2.10$ \\\\\n",
      "\\textbf{CW} & $97.93 \\pm 0.02$ & $96.04 \\pm 0.16$ & $89.82 \\pm 0.35$ & $85.36 \\pm 0.43$ & $71.69 \\pm 0.82$ & $68.03 \\pm 0.17$ & $77.58 \\pm 0.02$ & $73.29 \\pm 0.08$ & $53.63 \\pm 2.28$ & $51.68 \\pm 2.49$ \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = \"\"\n",
    "for j in range(lid_mean.shape[1]):\n",
    "    latex_table += \"\\\\textbf{\"+f\"{attacks[j].upper()}\"+\"} & \"\n",
    "    for i in range(lid_mean.shape[0]):\n",
    "        mean = lid_mean[i, j, 0]\n",
    "        variance = lid_var[i, j, 0]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "        mean = lid_mean[i, j, 1]\n",
    "        variance = lid_var[i, j, 1]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "    latex_table = latex_table[:-2] + \"\\\\\\\\\\n\"\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64bcf9-6e29-4896-920d-dfa5a7c2b9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cuda--11-1-1--pytorch--1-9-0]",
   "language": "python",
   "name": "conda-env-.conda-cuda--11-1-1--pytorch--1-9-0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
