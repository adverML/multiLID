{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0be57e-6e73-404d-b94c-0c083affa5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from numpy import random\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "home = str(Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6bae7c8-dfac-4179-88a2-06c1b5137130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, y_train, X_test, y_test):\n",
    "    scaler  = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    clf = LogisticRegressionCV(n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat =    clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8323319-9c2f-4a2c-ae43-032b67edb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_train, y_train, X_test, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=300, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat =    clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3e8d54-85f9-4358-859b-26c5fc74e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state:  21\n",
      "random state:  30\n",
      "random state:  65\n"
     ]
    }
   ],
   "source": [
    "factor = 0.8\n",
    "nr_mean = 3\n",
    "mean_tables = []\n",
    "nr_samples=2000\n",
    "\n",
    "datasets = ['cifar10', 'cifar100', 'imagenet']\n",
    "models = ['wrn28-10', 'vgg16', 'wrn50-2']\n",
    "attacks = ['fgsm', 'bim', 'pgd', 'aa', 'df', 'cw']\n",
    "detectors = ['lid', 'multilid']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for it in range(nr_mean):\n",
    "    random_state = [21, 30, 65][it] # random.randint(100)\n",
    "    print(\"random state: \", random_state)\n",
    "    final_table = np.zeros((len(attacks), 2))\n",
    "    \n",
    "    results[it] = {}\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        if dataset == 'imagenet':\n",
    "            k=30\n",
    "        else:\n",
    "            k=20\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            \n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "                \n",
    "            if not dataset in results[it]:\n",
    "                results[it][dataset] = {}\n",
    "            if not model in results[it][dataset]:\n",
    "                results[it][dataset][model] = {}\n",
    "                \n",
    "            #print(\"config: \", random_state, dataset, model)\n",
    "            \n",
    "            for detector in detectors:\n",
    "                base_path = os.path.join(home, 'workspace/multiLID/data/extract/run_{}/'.format(it+1))\n",
    "                nor_fgsm  = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/fgsm/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_fgsm  = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/fgsm/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_bim   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/bim/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_bim   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/bim/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_pgd   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/pgd/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_pgd   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/pgd/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_aa    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/aa/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_aa    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/aa/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_df    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/df/k{k}/{detector}_normalos.pt\"))\n",
    "                adv_df    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/df/k{k}/{detector}_adverlos.pt\"))\n",
    "                nor_cw    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/cw/k{k}/{detector}_normalos.pt\"))\n",
    "                adv_cw    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/cw/k{k}/{detector}_adverlos.pt\"))\n",
    "\n",
    "                nor = [nor_fgsm, nor_bim, nor_pgd, nor_aa, nor_df, nor_cw]\n",
    "                adv = [adv_fgsm, adv_bim, adv_pgd, adv_aa, adv_df, adv_cw]\n",
    "\n",
    "                for rows in range(len(nor)):\n",
    "                    X_nor = nor[rows]\n",
    "                    X_adv = adv[rows]\n",
    "                    if len(X_nor.shape) > 2: \n",
    "                        X_nor = nor[rows].reshape((nor[rows].shape[0], -1))\n",
    "                        X_adv = adv[rows].reshape((adv[rows].shape[0], -1))\n",
    "\n",
    "                    y_nor = np.zeros(X_nor.shape[0]).astype('int')\n",
    "                    y_adv = np.ones(X_nor.shape[0]).astype('int')\n",
    "\n",
    "                    x_train_n, x_test_n, y_train_n, y_test_n = train_test_split(X_nor, y_nor, test_size=1-factor, train_size=factor, random_state=random_state)\n",
    "                    x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(X_adv, y_adv, test_size=1-factor, train_size=factor, random_state=random_state)\n",
    "\n",
    "                    X_train = np.concatenate((x_train_n, x_train_a))\n",
    "                    y_train = np.concatenate((y_train_n, y_train_a))\n",
    "\n",
    "                    X_test = np.concatenate((x_test_n, x_test_a))\n",
    "                    y_test = np.concatenate((y_test_n, y_test_a))\n",
    "\n",
    "                    if detector == 'lid':\n",
    "                        y_hat, y_hat_pr = LR(X_train, y_train, X_test, y_test)\n",
    "                    elif detector == 'multilid':\n",
    "                        y_hat, y_hat_pr = RF(X_train, y_train, X_test, y_test)\n",
    "\n",
    "                    auc = round(100*roc_auc_score(y_test, y_hat_pr), 2)\n",
    "                    f1 =  round(100*f1_score(y_test, y_hat), 2)\n",
    "     \n",
    "                    if not detector in results[it][dataset][model]:\n",
    "                        results[it][dataset][model][detector] = {}\n",
    "                    \n",
    "                    if not attacks[rows] in results[it][dataset][model][detector]: \n",
    "                        results[it][dataset][model][detector][attacks[rows]] = {}\n",
    "                    \n",
    "                    \n",
    "                    if not 'auc' in results[it][dataset][model][detector][attacks[rows]]:\n",
    "                        results[it][dataset][model][detector][attacks[rows]]['auc'] = {}\n",
    "                    if not 'f1' in results[it][dataset][model][detector][attacks[rows]]:\n",
    "                        results[it][dataset][model][detector][attacks[rows]]['f1' ] = {}\n",
    "                        \n",
    "                    results[it][dataset][model][detector][attacks[rows]]['auc'] = auc\n",
    "                    results[it][dataset][model][detector][attacks[rows]]['f1'] = f1                    \n",
    "\n",
    "                    # print(attacks[rows].upper(), '&' , auc, '&', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97bf8ab6-2bbe-48ec-bf1c-0c74b7ae8ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0 & 93.02 & 87.62 & 79.74 & 99.05 & 94.89 & 77.36 & 71.16 & 72.83 & 66.16 \\\\ \n",
      "87.04 & 80.59 & 91.14 & 83.69 & 96.04 & 88.66 & 83.62 & 76.75 & 95.09 & 88.53 \\\\ \n",
      "88.34 & 78.73 & 91.2 & 83.27 & 98.1 & 92.6 & 83.7 & 76.96 & 95.31 & 88.0 \\\\ \n",
      "97.32 & 91.56 & 97.5 & 92.25 & 99.51 & 96.59 & 87.02 & 78.87 & 99.95 & 99.75 \\\\ \n",
      "95.53 & 87.95 & 86.99 & 75.82 & 56.5 & 52.73 & 54.58 & 54.01 & 54.86 & 51.38 \\\\ \n",
      "94.5 & 85.35 & 83.87 & 75.64 & 54.66 & 51.79 & 61.89 & 60.24 & 54.19 & 47.58 \\\\ \n"
     ]
    }
   ],
   "source": [
    "lid_list = []\n",
    "\n",
    "for dataset in ['cifar10', 'cifar100', 'imagenet']:\n",
    "    for model in ['wrn28-10', 'vgg16', 'wrn50-2']:\n",
    "        if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "            continue\n",
    "\n",
    "        if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "            continue\n",
    "        \n",
    "        tmp = np.zeros((6, 2))\n",
    "        for it, val in enumerate(results[0][dataset][model]['lid'].items()):\n",
    "            #print(it, val)\n",
    "            tmp[it, 0] = val[1]['auc'].copy()\n",
    "            tmp[it, 1] = val[1]['f1'].copy()\n",
    "        lid_list.append(tmp.copy())\n",
    "\n",
    "result_table = np.concatenate(lid_list, axis=1)\n",
    "for row in result_table:\n",
    "    for i, val in enumerate(row):\n",
    "        print(val, end='')\n",
    "        if (i+1) % 1 == 0 and i != len(row)-1:\n",
    "            print(' & ', end='')\n",
    "        elif i != len(row)-1:\n",
    "            print(' ', end='')\n",
    "    print(\" \\\\\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781911fb-87e8-4881-8921-ca586ed1959e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_list = []\n",
    "\n",
    "for dataset in ['cifar10', 'cifar100', 'imagenet']:\n",
    "    for model in ['wrn28-10', 'vgg16', 'wrn50-2']:\n",
    "        if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "            continue\n",
    "\n",
    "        if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "            continue\n",
    "        \n",
    "        tmp = np.zeros((6, 2))\n",
    "        for it, val in enumerate(results[0][dataset][model]['multilid'].items()):\n",
    "            \n",
    "            print(it, val)\n",
    "            tmp[it, 0] = val[1]['auc'].copy()\n",
    "            tmp[it, 1] = val[1]['f1'].copy()\n",
    "        lid_list.append(tmp.copy())\n",
    "\n",
    "result_table = np.concatenate(lid_list, axis=1)\n",
    "for row in result_table:\n",
    "    for i, val in enumerate(row):\n",
    "        print(val, end='')\n",
    "        if (i+1) % 1 == 0 and i != len(row)-1:\n",
    "            print(' & ', end='')\n",
    "        elif i != len(row)-1:\n",
    "            print(' ', end='')\n",
    "    print(\" \\\\\\ \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49db406d-8c71-4852-a84a-1d3bf5c2a9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cuda--11-1-1--pytorch--1-9-0]",
   "language": "python",
   "name": "conda-env-.conda-cuda--11-1-1--pytorch--1-9-0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
