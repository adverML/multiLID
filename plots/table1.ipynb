{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b0be57e-6e73-404d-b94c-0c083affa5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from numpy import random\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "home = str(Path.home())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6bae7c8-dfac-4179-88a2-06c1b5137130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR(X_train, y_train, X_test, y_test):\n",
    "    scaler  = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test  = scaler.transform(X_test)  \n",
    "    clf = LogisticRegression(n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat =    clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e3bf3a9-1fd2-44ac-9846-5634c6e9c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(clf, X_test, scaler=None):\n",
    "    if not scaler == None:\n",
    "        X_test   = scaler.transform(X_test)\n",
    "    y_hat    = clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b8323319-9c2f-4a2c-ae43-032b67edb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(X_train, y_train, X_test, y_test):\n",
    "    kwargs = {'n_estimators': 50, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 60, 'bootstrap': False}  \n",
    "\n",
    "    clf = RandomForestClassifier(n_jobs=-1, **kwargs)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_hat =    clf.predict(X_test)\n",
    "    y_hat_pr = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return y_hat, y_hat_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b3e8d54-85f9-4358-859b-26c5fc74e71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random state:  21\n",
      "random state:  30\n",
      "random state:  65\n"
     ]
    }
   ],
   "source": [
    "factor = 0.8\n",
    "nr_mean = 3\n",
    "mean_tables = []\n",
    "nr_samples=2000\n",
    "\n",
    "attacks = ['fgsm', 'bim', 'pgd', 'aa', 'df', 'cw']\n",
    "datasets = ['cifar10', 'cifar100', 'imagenet']\n",
    "models = ['wrn28-10', 'vgg16', 'wrn50-2']\n",
    "detectors = ['lid', 'multilid']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for it in range(nr_mean):\n",
    "    random_state = [21, 30, 65][it] # random.randint(100)\n",
    "    print(\"random state: \", random_state)\n",
    "    final_table = np.zeros((len(attacks), 2))\n",
    "    base_path = os.path.join(home, 'workspace/multiLID/data/extract/run_{}/'.format(it+1))\n",
    "    \n",
    "    results[it] = {}\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        \n",
    "        if dataset == 'imagenet':\n",
    "            k=30\n",
    "        else:\n",
    "            k=20\n",
    "        \n",
    "        for model in models:\n",
    "            \n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            \n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "                \n",
    "            if not dataset in results[it]:\n",
    "                results[it][dataset] = {}\n",
    "            if not model in results[it][dataset]:\n",
    "                results[it][dataset][model] = {}\n",
    "                \n",
    "            #print(\"config: \", random_state, dataset, model)\n",
    "            \n",
    "            for detector in detectors:\n",
    "                \n",
    "                nor_fgsm  = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/fgsm/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_fgsm  = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/fgsm/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_bim   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/bim/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_bim   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/bim/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_pgd   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/pgd/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_pgd   = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/pgd/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_aa    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/aa/k{k}/{detector}_normalos_8255.pt\"))\n",
    "                adv_aa    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/aa/k{k}/{detector}_adverlos_8255.pt\"))\n",
    "                nor_df    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/df/k{k}/{detector}_normalos.pt\"))\n",
    "                adv_df    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/df/k{k}/{detector}_adverlos.pt\"))\n",
    "                nor_cw    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/cw/k{k}/{detector}_normalos.pt\"))\n",
    "                adv_cw    = torch.load(os.path.join(base_path,  f\"{dataset}/{model}/{detector}/cw/k{k}/{detector}_adverlos.pt\"))\n",
    "\n",
    "                nor = [nor_fgsm, nor_bim, nor_pgd, nor_aa, nor_df, nor_cw]\n",
    "                adv = [adv_fgsm, adv_bim, adv_pgd, adv_aa, adv_df, adv_cw]\n",
    "\n",
    "                for rows in range(len(nor)):\n",
    "                    X_nor = nor[rows]\n",
    "                    X_adv = adv[rows]\n",
    "                    if len(X_nor.shape) > 2: \n",
    "                        X_nor = nor[rows].reshape((nor[rows].shape[0], -1))\n",
    "                        X_adv = adv[rows].reshape((adv[rows].shape[0], -1))\n",
    "\n",
    "                    y_nor = np.zeros(X_nor.shape[0]).astype('int')\n",
    "                    y_adv = np.ones(X_nor.shape[0]).astype('int')\n",
    "\n",
    "                    x_train_n, x_test_n, y_train_n, y_test_n = train_test_split(X_nor, y_nor, test_size=1-factor, train_size=factor, random_state=random_state)\n",
    "                    x_train_a, x_test_a, y_train_a, y_test_a = train_test_split(X_adv, y_adv, test_size=1-factor, train_size=factor, random_state=random_state)\n",
    "\n",
    "                    X_train = np.concatenate((x_train_n, x_train_a))\n",
    "                    y_train = np.concatenate((y_train_n, y_train_a))\n",
    "\n",
    "                    X_test = np.concatenate((x_test_n, x_test_a))\n",
    "                    y_test = np.concatenate((y_test_n, y_test_a))\n",
    "\n",
    "                    if detector == 'lid':\n",
    "                        y_hat, y_hat_pr = LR(X_train, y_train, X_test, y_test)\n",
    "                    elif detector == 'multilid':\n",
    "                        y_hat, y_hat_pr = RF(X_train, y_train, X_test, y_test)\n",
    "\n",
    "                    auc = round(100*roc_auc_score(y_test, y_hat_pr), 2)\n",
    "                    f1 =  round(100*f1_score(y_test, y_hat), 2)\n",
    "     \n",
    "                    if not detector in results[it][dataset][model]:\n",
    "                        results[it][dataset][model][detector] = {}\n",
    "                    \n",
    "                    if not attacks[rows] in results[it][dataset][model][detector]: \n",
    "                        results[it][dataset][model][detector][attacks[rows]] = {}\n",
    "                    \n",
    "                    \n",
    "                    if not 'auc' in results[it][dataset][model][detector][attacks[rows]]:\n",
    "                        results[it][dataset][model][detector][attacks[rows]]['auc'] = {}\n",
    "                    if not 'f1' in results[it][dataset][model][detector][attacks[rows]]:\n",
    "                        results[it][dataset][model][detector][attacks[rows]]['f1' ] = {}\n",
    "                        \n",
    "                    results[it][dataset][model][detector][attacks[rows]]['auc'] = auc\n",
    "                    results[it][dataset][model][detector][attacks[rows]]['f1'] = f1                    \n",
    "\n",
    "                    # print(attacks[rows].upper(), '&' , auc, '&', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e74111-ee97-4fb9-bf13-23c6725d54fa",
   "metadata": {},
   "source": [
    "# LID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97bf8ab6-2bbe-48ec-bf1c-0c74b7ae8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_list_mean = []\n",
    "for it_mean in range(nr_mean):\n",
    "    lid_list = []\n",
    "    for dataset in ['cifar10', 'cifar100', 'imagenet']:\n",
    "        for model in ['wrn28-10', 'vgg16', 'wrn50-2']:\n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "            \n",
    "            tmp = np.zeros((len(attacks), 2))\n",
    "            for it, val in enumerate(results[it_mean][dataset][model]['lid'].items()):\n",
    "                #print(it, val)\n",
    "                tmp[it, 0] = val[1]['auc'].copy()\n",
    "                tmp[it, 1] = val[1]['f1'].copy()\n",
    "            lid_list.append(tmp.copy())\n",
    "    \n",
    "    lid_list_mean.append(np.stack(lid_list))\n",
    "lid_list_mean_res = np.stack(lid_list_mean)\n",
    "lid_mean = np.mean(lid_list_mean_res, axis=0)\n",
    "lid_var = np.var(lid_list_mean_res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d671e4af-b99b-4f77-aaae-84c0d5626b72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{FGSM} & $96.07 \\pm 0.07$ & $89.58 \\pm 0.16$ & $88.11 \\pm 0.25$ & $79.36 \\pm 0.34$ & $98.21 \\pm 0.48$ & $93.61 \\pm 1.57$ & $77.98 \\pm 1.19$ & $70.75 \\pm 0.58$ & $71.44 \\pm 8.46$ & $66.22 \\pm 2.31$ \\\\\n",
      "\\textbf{BIM} & $87.09 \\pm 0.21$ & $79.70 \\pm 0.40$ & $92.47 \\pm 1.69$ & $84.55 \\pm 1.31$ & $95.61 \\pm 0.90$ & $88.90 \\pm 0.74$ & $81.62 \\pm 3.42$ & $73.95 \\pm 5.96$ & $94.46 \\pm 0.28$ & $87.20 \\pm 1.25$ \\\\\n",
      "\\textbf{PGD} & $89.28 \\pm 0.62$ & $80.37 \\pm 2.37$ & $89.80 \\pm 0.39$ & $80.49 \\pm 1.79$ & $97.83 \\pm 0.06$ & $91.85 \\pm 0.12$ & $85.29 \\pm 1.20$ & $78.86 \\pm 1.92$ & $96.21 \\pm 0.43$ & $89.76 \\pm 2.03$ \\\\\n",
      "\\textbf{AA} & $96.86 \\pm 0.41$ & $91.13 \\pm 0.68$ & $97.06 \\pm 0.13$ & $91.03 \\pm 0.18$ & $99.32 \\pm 0.02$ & $95.61 \\pm 0.57$ & $87.27 \\pm 0.94$ & $79.05 \\pm 0.04$ & $99.97 \\pm 0.00$ & $99.45 \\pm 0.11$ \\\\\n",
      "\\textbf{DF} & $95.37 \\pm 0.04$ & $87.71 \\pm 2.39$ & $86.46 \\pm 0.26$ & $77.00 \\pm 1.03$ & $57.04 \\pm 0.62$ & $53.01 \\pm 0.71$ & $54.41 \\pm 0.03$ & $53.12 \\pm 0.55$ & $54.65 \\pm 0.11$ & $49.84 \\pm 1.15$ \\\\\n",
      "\\textbf{CW} & $94.14 \\pm 0.15$ & $85.59 \\pm 0.16$ & $83.66 \\pm 0.34$ & $74.81 \\pm 0.59$ & $55.08 \\pm 0.37$ & $53.21 \\pm 5.30$ & $61.85 \\pm 1.10$ & $62.05 \\pm 1.79$ & $54.49 \\pm 0.03$ & $50.52 \\pm 3.62$ \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = \"\"\n",
    "for j in range(lid_mean.shape[1]):\n",
    "    latex_table += \"\\\\textbf{\"+f\"{attacks[j].upper()}\"+\"} & \"\n",
    "    for i in range(lid_mean.shape[0]):\n",
    "        mean = lid_mean[i, j, 0]\n",
    "        variance = lid_var[i, j, 0]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "        mean = lid_mean[i, j, 1]\n",
    "        variance = lid_var[i, j, 1]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "    latex_table = latex_table[:-2] + \"\\\\\\\\\\n\"\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d4fba-1ac2-4e5c-9b74-32044fec423f",
   "metadata": {},
   "source": [
    "# multiLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d09c5b4-36d6-4815-8b46-3f9c1f82d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "lid_list_mean = []\n",
    "for it_mean in range(nr_mean):\n",
    "    lid_list = []\n",
    "    for dataset in ['cifar10', 'cifar100', 'imagenet']:\n",
    "        for model in ['wrn28-10', 'vgg16', 'wrn50-2']:\n",
    "            if dataset in ['cifar10', 'cifar100'] and model in ['wrn50-2']:\n",
    "                continue\n",
    "            if dataset in ['imagenet'] and model in  ['wrn28-10', 'vgg16']:\n",
    "                continue\n",
    "            \n",
    "            tmp = np.zeros((len(attacks), 2))\n",
    "            for it, val in enumerate(results[it_mean][dataset][model]['multilid'].items()):\n",
    "                #print(it, val)\n",
    "                tmp[it, 0] = val[1]['auc'].copy()\n",
    "                tmp[it, 1] = val[1]['f1'].copy()\n",
    "            lid_list.append(tmp.copy())\n",
    "    \n",
    "    lid_list_mean.append(np.stack(lid_list))\n",
    "lid_list_mean_res = np.stack(lid_list_mean)\n",
    "lid_mean = np.mean(lid_list_mean_res, axis=0)\n",
    "lid_var = np.var(lid_list_mean_res, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f42bc221-06c4-4041-b198-fc5d9706c122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{FGSM} & $96.98 \\pm 0.20$ & $91.19 \\pm 0.95$ & $90.78 \\pm 0.38$ & $82.34 \\pm 1.37$ & $98.55 \\pm 0.28$ & $94.80 \\pm 1.32$ & $83.00 \\pm 0.84$ & $76.89 \\pm 0.02$ & $79.25 \\pm 2.75$ & $72.98 \\pm 0.67$ \\\\\n",
      "\\textbf{BIM} & $96.10 \\pm 0.39$ & $89.93 \\pm 1.24$ & $94.50 \\pm 0.26$ & $88.14 \\pm 0.43$ & $97.88 \\pm 0.07$ & $91.72 \\pm 0.09$ & $82.96 \\pm 0.94$ & $75.42 \\pm 1.39$ & $94.48 \\pm 0.18$ & $86.92 \\pm 0.93$ \\\\\n",
      "\\textbf{PGD} & $97.69 \\pm 0.12$ & $92.81 \\pm 0.37$ & $92.35 \\pm 1.46$ & $83.52 \\pm 3.46$ & $98.76 \\pm 0.05$ & $94.74 \\pm 1.14$ & $88.39 \\pm 0.06$ & $81.42 \\pm 0.44$ & $96.39 \\pm 0.11$ & $90.21 \\pm 0.49$ \\\\\n",
      "\\textbf{AA} & $99.45 \\pm 0.03$ & $96.88 \\pm 0.00$ & $98.77 \\pm 0.08$ & $94.85 \\pm 1.42$ & $99.85 \\pm 0.00$ & $98.33 \\pm 0.01$ & $91.25 \\pm 0.33$ & $83.48 \\pm 0.17$ & $99.90 \\pm 0.00$ & $98.83 \\pm 0.04$ \\\\\n",
      "\\textbf{DF} & $97.51 \\pm 0.12$ & $94.04 \\pm 0.26$ & $89.37 \\pm 2.42$ & $84.32 \\pm 0.83$ & $74.75 \\pm 0.16$ & $70.18 \\pm 0.57$ & $73.78 \\pm 1.12$ & $70.04 \\pm 0.09$ & $52.93 \\pm 1.01$ & $52.77 \\pm 1.89$ \\\\\n",
      "\\textbf{CW} & $97.92 \\pm 0.01$ & $96.00 \\pm 0.11$ & $89.75 \\pm 0.21$ & $85.27 \\pm 0.85$ & $70.10 \\pm 1.33$ & $67.77 \\pm 0.85$ & $76.15 \\pm 0.20$ & $71.59 \\pm 0.20$ & $53.37 \\pm 0.01$ & $52.04 \\pm 0.17$ \\\\\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = \"\"\n",
    "for j in range(lid_mean.shape[1]):\n",
    "    latex_table += \"\\\\textbf{\"+f\"{attacks[j].upper()}\"+\"} & \"\n",
    "    for i in range(lid_mean.shape[0]):\n",
    "        mean = lid_mean[i, j, 0]\n",
    "        variance = lid_var[i, j, 0]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "        mean = lid_mean[i, j, 1]\n",
    "        variance = lid_var[i, j, 1]\n",
    "        latex_table += f\"${mean:.2f} \\\\pm {variance:.2f}$ & \"\n",
    "    latex_table = latex_table[:-2] + \"\\\\\\\\\\n\"\n",
    "\n",
    "# Print the LaTeX table\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cuda--11-1-1--pytorch--1-9-0]",
   "language": "python",
   "name": "conda-env-.conda-cuda--11-1-1--pytorch--1-9-0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
